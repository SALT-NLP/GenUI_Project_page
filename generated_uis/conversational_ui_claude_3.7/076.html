<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Early Detection of Neurodegenerative Diseases from Speech</title>
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', (event) => {
      // Apply syntax highlighting to code blocks
      document.querySelectorAll('pre code').forEach((el) => {
        hljs.highlightElement(el);
      });
    });
  </script>
  <style>
    .message-content {
      overflow-wrap: break-word;
      word-wrap: break-word;
      word-break: break-word;
      hyphens: auto;
      max-width: 100%;
    }

    .message-content img {
      max-width: 100%;
      height: auto;
    }

    .message-content pre {
      max-width: 100%;
      overflow-x: auto;
      white-space: pre-wrap;
    }

    .message-content code {
      white-space: pre-wrap;
    }

    .message-content table {
      width: 100%;
      max-width: 100%;
      border-collapse: collapse;
      margin: 1rem 0;
      overflow-x: auto;
      display: block;
    }

    .message-content table td,
    .message-content table th {
      border: 1px solid var(--color-assistant-bubble-border);
      padding: 0.5rem;
      text-align: left;
    }

    .message-content table th {
      background-color: var(--color-assistant-bubble);
    }

    .message-content ul,
    .message-content ol {
      padding-left: 2rem;
      margin: 0.5rem 0;
    }

    .message-content ul li,
    .message-content ol li {
      margin-bottom: 0.25rem;
    }


    .artifacts-section {
      margin-top: 30px;
      padding: 15px;
      background-color: var(--color-assistant-bubble);
      border-radius: var(--radius-lg);
      border: 1px solid var(--color-assistant-bubble-border);
    }

    .artifacts-section h2 {
      margin-top: 0;
      color: var(--color-header);
      font-size: 1.2rem;
    }

    .artifacts-list {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
      gap: 10px;
    }

    .artifact-item {
      background: white;
      padding: 10px;
      border-radius: var(--radius-sm);
      box-shadow: var(--shadow-sm);
      transition: transform 0.2s, box-shadow 0.2s;
    }

    .artifact-item:hover {
      transform: translateY(-2px);
      box-shadow: var(--shadow-md);
    }

    .artifact-link {
      text-decoration: none;
      color: var(--color-text);
      display: block;
    }

    .artifact-title {
      font-weight: 600;
      margin-bottom: 5px;
      color: var(--color-accent);
    }

    .artifact-type {
      font-size: 0.8rem;
      color: var(--color-text-secondary);
    }


    .embedded-artifact-reference {
      margin: 15px 0;
      text-align: center;
    }

    .artifact-button {
      display: inline-block;
      background-color: var(--color-accent);
      color: white;
      padding: 10px 20px;
      border-radius: var(--radius-sm);
      text-decoration: none;
      font-weight: 500;
      box-shadow: var(--shadow-sm);
      transition: transform 0.2s, box-shadow 0.2s;
    }

    .artifact-button:hover {
      transform: translateY(-2px);
      box-shadow: var(--shadow-md);
    }
  </style>
</head>

<body>
  <div class="container">
    <header>
      <h1>Early Detection of Neurodegenerative Diseases from Speech</h1>
      <button class="back-button" style="display: none;" onclick="history.back()">Go Back</button>
    </header>

    <div class="conversation-container">

      <div class="message user">
        <div class="message-header">
          <div class="message-avatar avatar-user">
            U
          </div>
          <div class="message-author">You</div>
          <div class="message-time">5/1/2025, 2:02:26 AM</div>
        </div>
        <div class="message-content">
          <p>I'm part of a research team using machine learning to detect early signs of neurodegenerative diseases from
            speech patterns. We have a dataset of recorded interviews from both healthy individuals and those with
            early-stage conditions, but it's relatively small (200 subjects). What approaches would be most effective
            for feature extraction from audio data? How can we build robust models with limited training data that
            generalize well to diverse speech patterns and accents?</p>
        </div>
      </div>


      <div class="message assistant">
        <div class="message-header">
          <div class="message-avatar avatar-assistant">
            A
          </div>
          <div class="message-author">Assistant</div>
          <div class="message-time">5/1/2025, 2:02:38 AM</div>
        </div>
        <div class="message-content">
          <p> I&#39;d be happy to help with your research on using machine learning to detect early signs of
            neurodegenerative diseases from speech patterns. This is a fascinating area with significant potential
            impact on early diagnosis and intervention.</p>
          <p>Given your limited dataset size (200 subjects), here are some effective approaches for feature extraction
            and building robust models:</p>
          <h2>Feature Extraction from Speech Audio</h2>
          <ol class="markdown-list">
            <li>
              <p><strong>Acoustic features</strong>:</p>
              <ul class="markdown-list">
                <li>Fundamental frequency (pitch) and its statistics (mean, variance, jitter)</li>
                <li>Voice quality measures (shimmer, harmonics-to-noise ratio)</li>
                <li>Formant frequencies and their trajectories</li>
                <li>Speaking rate and rhythm metrics</li>
                <li>Pause patterns (frequency, duration, distribution)</li>
              </ul>
            </li>
            <li>
              <p><strong>Spectral features</strong>:</p>
              <ul class="markdown-list">
                <li>Mel-frequency cepstral coefficients (MFCCs)</li>
                <li>Spectral centroids, flux, and entropy</li>
                <li>Linear prediction coefficients</li>
                <li>Wavelets for time-frequency analysis</li>
              </ul>
            </li>
            <li>
              <p><strong>Prosodic features</strong>:</p>
              <ul class="markdown-list">
                <li>Intonation patterns and variability</li>
                <li>Stress patterns</li>
                <li>Rhythm metrics (pairwise variability index, speech rhythm)</li>
              </ul>
            </li>
          </ol>
          <h2>Strategies for Limited Data</h2>
          <ol class="markdown-list">
            <li>
              <p><strong>Transfer learning</strong>:</p>
              <ul class="markdown-list">
                <li>Use pre-trained audio models (e.g., wav2vec 2.0, HuBERT) that have been trained on large speech
                  corpora</li>
                <li>Fine-tune these models on your specific task with your limited dataset</li>
                <li>Consider models pre-trained on related health tasks if available</li>
              </ul>
            </li>
            <li>
              <p><strong>Data augmentation techniques</strong>:</p>
              <ul class="markdown-list">
                <li>Time stretching/compression (changing speed without pitch)</li>
                <li>Pitch shifting (within reasonable bounds)</li>
                <li>Adding minimal background noise</li>
                <li>Room impulse response simulation (different acoustic environments)</li>
                <li>Selective augmentation that preserves clinically relevant features</li>
              </ul>
            </li>
            <li>
              <p><strong>Dimensionality reduction</strong>:</p>
              <ul class="markdown-list">
                <li>Principal Component Analysis (PCA)</li>
                <li>t-SNE for visualization</li>
                <li>Feature selection based on clinical relevance</li>
              </ul>
            </li>
          </ol>
          <h2>Model Approaches</h2>
          <ol class="markdown-list">
            <li>
              <p><strong>Ensemble methods</strong>:</p>
              <ul class="markdown-list">
                <li>Random forests</li>
                <li>Gradient boosting machines</li>
                <li>Model stacking with diverse base learners</li>
              </ul>
            </li>
            <li>
              <p><strong>Regularization techniques</strong>:</p>
              <ul class="markdown-list">
                <li>L1/L2 regularization</li>
                <li>Dropout for neural network approaches</li>
                <li>Early stopping based on validation performance</li>
              </ul>
            </li>
            <li>
              <p><strong>Cross-validation strategies</strong>:</p>
              <ul class="markdown-list">
                <li>Leave-one-subject-out cross-validation</li>
                <li>Stratified k-fold to maintain class distributions</li>
                <li>Repeated cross-validation for more robust estimates</li>
              </ul>
            </li>
            <li>
              <p><strong>Interpretable models</strong>:</p>
              <ul class="markdown-list">
                <li>Explainable AI techniques to understand which features contribute most</li>
                <li>This can provide clinical insights and verify the model is using relevant patterns</li>
              </ul>
            </li>
          </ol>
          <h2>Handling Diverse Speech Patterns and Accents</h2>
          <ol class="markdown-list">
            <li>
              <p><strong>Demographics-aware sampling</strong>:</p>
              <ul class="markdown-list">
                <li>Ensure training data includes diverse speech patterns and accents</li>
                <li>Consider stratified sampling approaches in cross-validation</li>
              </ul>
            </li>
            <li>
              <p><strong>Feature normalization</strong>:</p>
              <ul class="markdown-list">
                <li>Speaker-level normalization</li>
                <li>Z-score normalization within demographic groups</li>
                <li>Relative features that capture change rather than absolute values</li>
              </ul>
            </li>
            <li>
              <p><strong>Domain adaptation techniques</strong>:</p>
              <ul class="markdown-list">
                <li>Adversarial training to make features invariant to accent</li>
                <li>Multi-task learning (predict disease and demographic factors)</li>
              </ul>
            </li>
          </ol>
          <p>Would you like me to elaborate on any particular aspect of these approaches? Or would you prefer more
            specific technical details about implementing any of these methods?</p>
        </div>
      </div>

    </div>


  </div>

</body>

</html>