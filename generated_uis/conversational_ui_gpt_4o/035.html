<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Image Recognition Overview</title>
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', (event) => {
      // Apply syntax highlighting to code blocks
      document.querySelectorAll('pre code').forEach((el) => {
        hljs.highlightElement(el);
      });
    });
  </script>
</head>

<body>
  <div class="container">
    <header>
      <h1>Image Recognition Overview</h1>
      <button class="back-button" style="display: none;" onclick="history.back()">Go Back</button>
    </header>

    <div class="conversation-container">

      <div class="message user">
        <div class="message-header">
          <div class="message-avatar avatar-user">
            U
          </div>
          <div class="message-author">You</div>
          <div class="message-time">5/3/2025, 10:35:53 AM</div>
        </div>
        <div class="message-content">
          <p>I need to understand how image recognition works.</p>
        </div>
      </div>

      <div class="message assistant">
        <div class="message-header">
          <div class="message-avatar avatar-assistant">
            A
          </div>
          <div class="message-author">Assistant</div>
          <div class="message-time">5/3/2025, 10:35:53 AM</div>
        </div>
        <div class="message-content">
          <p>Image recognition is a process by which computers interpret and identify the content of digital images.
            It’s a major application of <strong>computer vision</strong> and typically involves <strong>machine
              learning</strong>, especially <strong>deep learning</strong> using neural networks.</p>
          <p>Here’s a breakdown of how it works:</p>
          <hr>
          <h3>1. <strong>Input: An Image</strong></h3>
          <p>A digital image (e.g., a photo) is input as a grid of pixels. Each pixel has color values (e.g., RGB).</p>
          <hr>
          <h3>2. <strong>Preprocessing</strong></h3>
          <p>Images are often resized, normalized, or converted to grayscale depending on the model being used. This
            step ensures consistency and better performance.</p>
          <hr>
          <h3>3. <strong>Feature Extraction (Traditionally)</strong></h3>
          <p>Earlier methods used manual feature extraction:</p>
          <ul>
            <li><strong>Edges</strong> (e.g., using filters like Sobel)</li>
            <li><strong>Corners</strong></li>
            <li><strong>Textures</strong><br>These features were then passed to a classifier (like SVM, decision trees).
            </li>
          </ul>
          <hr>
          <h3>4. <strong>Deep Learning Approach (Modern)</strong></h3>
          <p>Now, deep learning automates feature extraction:</p>
          <h4>a. <strong>Convolutional Neural Networks (CNNs)</strong></h4>
          <p>CNNs are the most common models for image recognition. They consist of:</p>
          <ul>
            <li><strong>Convolutional layers</strong>: Automatically detect patterns (like edges, shapes, textures).
            </li>
            <li><strong>Pooling layers</strong>: Reduce the spatial size (helps with performance).</li>
            <li><strong>Fully connected layers</strong>: Interpret the high-level features and output predictions.</li>
          </ul>
          <p>Each layer of the network identifies increasingly complex features — for example:</p>
          <ul>
            <li>Layer 1: Edges</li>
            <li>Layer 2: Corners or textures</li>
            <li>Layer 3: Object parts</li>
            <li>Layer N: Full objects (e.g., a dog’s face)</li>
          </ul>
          <hr>
          <h3>5. <strong>Classification</strong></h3>
          <p>The final layer often uses <strong>softmax</strong> to output probabilities for each possible class (e.g.,
            cat: 0.9, dog: 0.1).</p>
          <hr>
          <h3>6. <strong>Training the Model</strong></h3>
          <p>The system is trained on labeled datasets (like ImageNet). During training:</p>
          <ul>
            <li>It compares predictions to actual labels.</li>
            <li>It uses <strong>backpropagation</strong> to adjust internal weights and improve accuracy.</li>
          </ul>
          <hr>
          <h3>7. <strong>Inference</strong></h3>
          <p>Once trained, the model can be used to identify new images, even those it hasn&#39;t seen before.</p>
          <hr>
          <p>Would you like a visual diagram of this process?</p>
        </div>
      </div>

    </div>
  </div>
</body>

</html>