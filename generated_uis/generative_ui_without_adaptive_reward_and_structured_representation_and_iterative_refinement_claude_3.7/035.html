<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How Image Recognition Works</title>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap">
    <style>
        :root {
            --primary-color: #007bff;
            --secondary-color: #6c757d;
            --accent-color: #28a745;
            --background-color: #f8f9fa;
            --surface-color: #ffffff;
            --text-color: #212529;
            --text-light-color: #6c757d;
            --border-color: #dee2e6;
            --shadow-color: rgba(0, 0, 0, 0.05);
            --spacing-unit: 16px;
            --border-radius: 8px;
            --transition-speed: 0.3s;
        }

        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            margin: 0;
            padding: 0;
            overflow-x: hidden;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 0 var(--spacing-unit);
        }

        header {
            background-color: var(--surface-color);
            padding: var(--spacing-unit) 0;
            box-shadow: 0 2px 4px var(--shadow-color);
            margin-bottom: calc(2 * var(--spacing-unit));
        }

        header h1 {
            text-align: center;
            color: var(--primary-color);
            margin: 0;
            font-size: 2.5em;
            font-weight: 700;
        }

        main {
            padding-bottom: calc(4 * var(--spacing-unit));
        }

        section {
            background-color: var(--surface-color);
            padding: calc(2 * var(--spacing-unit));
            margin-bottom: calc(3 * var(--spacing-unit));
            border-radius: var(--border-radius);
            box-shadow: 0 4px 8px var(--shadow-color);
            opacity: 0;
            transform: translateY(20px);
            transition: opacity var(--transition-speed) ease-out, transform var(--transition-speed) ease-out;
        }

        section.is-visible {
            opacity: 1;
            transform: translateY(0);
        }

        section h2 {
            color: var(--primary-color);
            margin-top: 0;
            margin-bottom: var(--spacing-unit);
            font-size: 1.8em;
            font-weight: 600;
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: calc(var(--spacing-unit) / 2);
        }

        section p {
            margin-bottom: var(--spacing-unit);
            color: var(--text-light-color);
        }

        .content-layout {
            display: flex;
            gap: calc(2 * var(--spacing-unit));
            align-items: center;
        }

        .content-layout.reverse {
            flex-direction: row-reverse;
        }

        .content-layout .text-content {
            flex: 1;
        }

        .content-layout .visual-content {
            flex: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 200px; /* Ensure some height even if image fails */
        }

        .visual-content img {
            max-width: 100%;
            height: auto;
            border-radius: var(--border-radius);
            border: 1px solid var(--border-color);
            box-shadow: 0 2px 6px var(--shadow-color);
        }

        .diagram {
            width: 100%;
            padding: var(--spacing-unit);
            background-color: var(--background-color);
            border-radius: var(--border-radius);
            border: 1px dashed var(--border-color);
            text-align: center;
            font-weight: 600;
            color: var(--secondary-color);
        }

        .diagram .step {
            display: inline-block;
            padding: calc(var(--spacing-unit) / 2) var(--spacing-unit);
            margin: calc(var(--spacing-unit) / 2);
            background-color: var(--primary-color);
            color: var(--surface-color);
            border-radius: calc(var(--border-radius) / 2);
            cursor: pointer;
            transition: background-color var(--transition-speed) ease;
            position: relative;
        }

        .diagram .step:hover {
            background-color: #0056b3; /* Darker shade of primary */
        }

        .diagram .arrow {
            display: inline-block;
            margin: 0 calc(var(--spacing-unit) / 2);
            color: var(--secondary-color);
            font-size: 1.5em;
            vertical-align: middle;
        }

        .interactive-area {
            margin-top: var(--spacing-unit);
            padding: var(--spacing-unit);
            background-color: #e9ecef; /* Light grey background */
            border-radius: var(--border-radius);
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: var(--spacing-unit);
        }

        .interactive-area button {
            padding: calc(var(--spacing-unit) / 2) var(--spacing-unit);
            background-color: var(--accent-color);
            color: var(--surface-color);
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            font-size: 1em;
            transition: background-color var(--transition-speed) ease, transform 0.1s ease;
        }

        .interactive-area button:hover {
            background-color: #218838; /* Darker shade of accent */
        }

        .interactive-area button:active {
            transform: scale(0.98);
        }

        .interactive-area img {
             max-width: 100%;
            height: auto;
            border-radius: var(--border-radius);
            border: 1px solid var(--border-color);
            box-shadow: 0 2px 6px var(--shadow-color);
        }

        /* Classification Visualization */
        .classification-results {
            margin-top: var(--spacing-unit);
            padding: var(--spacing-unit);
            background-color: #fff3cd; /* Light warning color */
            border: 1px solid #ffeeba;
            border-radius: var(--border-radius);
        }

        .classification-results h3 {
            margin-top: 0;
            color: #856404; /* Dark warning color */
            font-size: 1.2em;
        }

        .classification-results ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .classification-results li {
            margin-bottom: calc(var(--spacing-unit) / 2);
            padding: calc(var(--spacing-unit) / 4) 0;
            border-bottom: 1px dashed #ffeeba;
        }

         .classification-results li:last-child {
             border-bottom: none;
         }


        /* Responsive adjustments */
        @media (max-width: 768px) {
            header h1 {
                font-size: 2em;
            }

            section {
                padding: var(--spacing-unit);
            }

            section h2 {
                font-size: 1.5em;
            }

            .content-layout {
                flex-direction: column;
                gap: var(--spacing-unit);
            }

             .content-layout.reverse {
                flex-direction: column; /* Stack columns normally on small screens */
            }

            .content-layout .text-content,
            .content-layout .visual-content {
                flex: none;
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Understanding Image Recognition</h1>
        </div>
    </header>

    <main class="container">
        <section id="intro">
            <h2>What is Image Recognition?</h2>
            <div class="content-layout">
                <div class="text-content">
                    <p>Image recognition is a technology that enables computers to identify and categorize objects, people, text, and actions within images. It's a core component of computer vision and powers many modern applications, from facial recognition to autonomous vehicles.</p>
                    <p>Think of it as teaching a computer to "see" and understand the visual world, much like humans do. But how does a computer, which only understands numbers, interpret the complex patterns in an image?</p>
                </div>
                 <div class="visual-content">
                    <img src="https://placehold.co/400x250?text=Image+Recognition+Concept" alt="Conceptual image representing image recognition">
                </div>
            </div>
        </section>

        <section id="step1-input">
            <h2>Step 1: The Input Image</h2>
             <div class="content-layout reverse">
                <div class="text-content">
                    <p>Everything starts with an image. To a computer, an image is just a grid of numbers. For a color image, each pixel has three values (Red, Green, Blue) representing its color intensity. A grayscale image has one value per pixel representing brightness.</p>
                    <p>The size of the grid (width x height) and the number of color channels determine the total amount of data the computer needs to process. A typical image might be represented by millions of numbers!</p>
                </div>
                 <div class="visual-content">
                    <img src="https://placehold.co/400x250?text=Input+Image" alt="Example of an input image">
                </div>
            </div>
        </section>

        <section id="step2-preprocessing">
            <h2>Step 2: Preprocessing</h2>
            <div class="content-layout">
                <div class="text-content">
                    <p>Raw images can be noisy, vary in size, or have inconsistent lighting. Preprocessing prepares the image for analysis by standardizing it.</p>
                    <p>Common preprocessing steps include:</p>
                    <ul>
                        <li>**Resizing:** Scaling the image to a fixed dimension.</li>
                        <li>**Normalization:** Adjusting pixel values to a standard range (e.g., 0 to 1).</li>
                        <li>**Noise Reduction:** Smoothing out random variations in pixel data.</li>
                        <li>**Color Space Conversion:** Converting RGB to grayscale or other formats if needed.</li>
                    </ul>
                    <p>This step ensures that the subsequent analysis is more consistent and reliable.</p>
                </div>
                 <div class="visual-content">
                    <img src="https://placehold.co/400x250?text=Processed+Image" alt="Example of a preprocessed image">
                </div>
            </div>
        </section>

        <section id="step3-feature-extraction">
            <h2>Step 3: Feature Extraction</h2>
            <div class="content-layout reverse">
                <div class="text-content">
                    <p>This is where the computer starts looking for meaningful patterns, or "features," in the image. Instead of analyzing every single pixel individually, it identifies key characteristics that help distinguish objects.</p>
                    <p>These features can be simple, like edges, corners, and lines, or more complex, like textures, shapes, and specific patterns. Early methods used hand-designed algorithms, while modern approaches, especially with deep learning, learn to extract features automatically.</p>
                    <div class="interactive-area">
                        <p>Click below to see a conceptual example of edge detection:</p>
                        <button id="toggleEdgeDetection">Show Edge Detection</button>
                        <img id="featureImage" src="https://placehold.co/300x200?text=Original+Feature+Area" alt="Area before feature extraction">
                    </div>
                </div>
                 <div class="visual-content">
                    <div class="diagram">
                        <span class="step" data-step="input">Input Image</span>
                        <span class="arrow">→</span>
                        <span class="step" data-step="preprocessing">Preprocessing</span>
                        <span class="arrow">→</span>
                        <span class="step" data-step="feature-extraction">Feature Extraction</span>
                        <span class="arrow">→</span>
                        <span class="step" data-step="classification">Classification</span>
                        <span class="arrow">→</span>
                        <span class="step" data-step="output">Output</span>
                    </div>
                </div>
            </div>
        </section>

        <section id="step4-classification">
            <h2>Step 4: Classification</h2>
             <div class="content-layout">
                <div class="text-content">
                    <p>Once the features are extracted, the computer uses them to classify the image. This involves comparing the extracted features to patterns it has learned from a vast dataset of labeled images.</p>
                    <p>Machine learning models, particularly convolutional neural networks (CNNs) in modern systems, are trained to recognize which combinations of features correspond to specific categories (e.g., "cat," "dog," "car").</p>
                    <p>The output is typically a probability score for each possible category, indicating how likely the image belongs to that category.</p>
                     <div class="classification-results">
                        <h3>Conceptual Classification Output:</h3>
                        <ul>
                            <li>Cat: 92%</li>
                            <li>Dog: 5%</li>
                            <li>Tiger: 2%</li>
                            <li>Other: 1%</li>
                        </ul>
                    </div>
                </div>
                 <div class="visual-content">
                    <img src="https://placehold.co/400x250?text=Classification+Model" alt="Conceptual image representing a classification model">
                </div>
            </div>
        </section>

        <section id="conclusion">
            <h2>Conclusion</h2>
            <div class="content-layout">
                <div class="text-content">
                    <p>By following these steps – taking an input image, cleaning it up, extracting meaningful features, and using those features to classify it – a computer can effectively "recognize" what's in a picture.</p>
                    <p>This technology is constantly evolving, becoming more accurate and capable, opening up new possibilities in countless fields.</p>
                </div>
                 <div class="visual-content">
                     <img src="https://placehold.co/400x250?text=Image+Recognition+Applications" alt="Conceptual image representing applications of image recognition">
                 </div>
            </div>
        </section>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const sections = document.querySelectorAll('section');
            const featureImage = document.getElementById('featureImage');
            const toggleButton = document.getElementById('toggleEdgeDetection');
            let isEdgeDetected = false;

            // Function to check if an element is in the viewport
            const isInViewport = (element) => {
                const rect = element.getBoundingClientRect();
                return (
                    rect.top <= (window.innerHeight || document.documentElement.clientHeight) &&
                    rect.bottom >= 0 &&
                    rect.left <= (window.innerWidth || document.documentElement.clientWidth) &&
                    rect.right >= 0
                );
            };

            // Function to add 'is-visible' class to sections in viewport
            const checkVisibility = () => {
                sections.forEach(section => {
                    if (isInViewport(section)) {
                        section.classList.add('is-visible');
                    }
                });
            };

            // Check visibility on scroll and initial load
            window.addEventListener('scroll', checkVisibility);
            checkVisibility(); // Initial check

            // Feature Extraction Interaction
            toggleButton.addEventListener('click', () => {
                if (isEdgeDetected) {
                    featureImage.src = "https://placehold.co/300x200?text=Original+Feature+Area";
                    toggleButton.textContent = "Show Edge Detection";
                } else {
                    featureImage.src = "https://placehold.co/300x200?text=Edge+Detected";
                    toggleButton.textContent = "Show Original";
                }
                isEdgeDetected = !isEdgeDetected;
            });

             // Diagram Step Interaction (Conceptual - could be expanded)
             const diagramSteps = document.querySelectorAll('.diagram .step');
             diagramSteps.forEach(step => {
                 step.addEventListener('click', () => {
                     const stepId = step.getAttribute('data-step');
                     // In a more complex example, this could trigger a modal,
                     // highlight the corresponding section, or show a tooltip.
                     // For now, a simple console log or visual cue could be added.
                     console.log(`Clicked step: ${stepId}`);
                     // Example: Add a temporary highlight class
                     step.style.backgroundColor = '#dc3545'; // Red highlight
                     setTimeout(() => {
                          step.style.backgroundColor = 'var(--primary-color)'; // Reset color
                     }, 500);
                 });
                  // Add keyboard navigation for steps
                  step.setAttribute('tabindex', '0'); // Make steps focusable
                  step.addEventListener('keypress', (e) => {
                      if (e.key === 'Enter' || e.key === ' ') {
                          step.click(); // Trigger click event on Enter or Space
                      }
                  });
             });

             // Add focus styles for accessibility
             const interactiveElements = document.querySelectorAll('button, .diagram .step');
             interactiveElements.forEach(el => {
                 el.addEventListener('focus', () => {
                     el.style.outline = '2px solid var(--accent-color)';
                     el.style.outlineOffset = '3px';
                 });
                 el.addEventListener('blur', () => {
                     el.style.outline = 'none';
                     el.style.outlineOffset = '0';
                 });
             });
        });
    </script>
</body>
</html>
