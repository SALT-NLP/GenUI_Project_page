<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Guide</title>
    <style>
        :root {
            --primary: #4a6fa5;
            --secondary: #6b8cae;
            --accent: #ff7e5f;
            --background: #f8f9fa;
            --text: #333333;
            --light-gray: #e9ecef;
            --dark-gray: #495057;
            --success: #28a745;
            --warning: #ffc107;
            --info: #17a2b8;
            --card-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            --transition: all 0.3s ease;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            line-height: 1.6;
            color: var(--text);
            background-color: var(--background);
            padding: 0;
            margin: 0;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        header {
            background-color: var(--primary);
            color: white;
            padding: 1.5rem 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        header .container {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo {
            font-size: 1.8rem;
            font-weight: 700;
            display: flex;
            align-items: center;
        }

        .logo-icon {
            margin-right: 0.5rem;
            font-size: 2rem;
        }

        nav ul {
            display: flex;
            list-style: none;
        }

        nav li {
            margin-left: 1.5rem;
        }

        nav a {
            color: white;
            text-decoration: none;
            padding: 0.5rem;
            border-radius: 4px;
            transition: var(--transition);
        }

        nav a:hover {
            background-color: rgba(255, 255, 255, 0.1);
        }

        .hero {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            padding: 4rem 0;
            text-align: center;
        }

        .hero h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        .hero p {
            font-size: 1.2rem;
            max-width: 800px;
            margin: 0 auto 2rem;
        }

        .btn {
            display: inline-block;
            background-color: var(--accent);
            color: white;
            padding: 0.75rem 1.5rem;
            border-radius: 4px;
            text-decoration: none;
            font-weight: 600;
            transition: var(--transition);
            border: none;
            cursor: pointer;
        }

        .btn:hover {
            background-color: #ff6a4b;
            transform: translateY(-2px);
        }

        .btn-secondary {
            background-color: transparent;
            border: 2px solid white;
            margin-left: 1rem;
        }

        .btn-secondary:hover {
            background-color: rgba(255, 255, 255, 0.1);
        }

        section {
            padding: 4rem 0;
        }

        section h2 {
            text-align: center;
            margin-bottom: 2.5rem;
            font-size: 2rem;
            color: var(--primary);
        }

        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .feature-card {
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: var(--card-shadow);
            transition: var(--transition);
        }

        .feature-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }

        .feature-img {
            height: 200px;
            background-color: var(--light-gray);
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 4rem;
            color: var(--primary);
        }

        .feature-content {
            padding: 1.5rem;
        }

        .feature-content h3 {
            margin-bottom: 1rem;
            color: var(--primary);
        }

        .algorithms {
            background-color: var(--light-gray);
        }

        .algorithm-cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .algorithm-card {
            background: white;
            border-radius: 8px;
            padding: 1.5rem;
            box-shadow: var(--card-shadow);
            transition: var(--transition);
        }

        .algorithm-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }

        .algorithm-card h3 {
            color: var(--primary);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
        }

        .algorithm-card h3 span {
            margin-right: 0.5rem;
            font-size: 1.5rem;
        }

        .applications {
            background-color: white;
        }

        .application-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 2rem;
        }

        .application-item {
            border-radius: 8px;
            overflow: hidden;
            box-shadow: var(--card-shadow);
            transition: var(--transition);
        }

        .application-item:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }

        .application-img {
            height: 180px;
            background-color: var(--light-gray);
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 3rem;
            color: var(--primary);
        }

        .application-content {
            padding: 1.5rem;
            background-color: white;
        }

        .application-content h3 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }

        .rl-process {
            background-color: var(--light-gray);
        }

        .process-diagram {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            padding: 2rem;
            box-shadow: var(--card-shadow);
        }

        .diagram-container {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .diagram {
            width: 100%;
            height: 300px;
            position: relative;
            margin-bottom: 2rem;
        }

        .diagram-item {
            position: absolute;
            width: 120px;
            height: 60px;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: var(--primary);
            color: white;
            border-radius: 8px;
            font-weight: 600;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .diagram-arrow {
            position: absolute;
            background-color: var(--dark-gray);
            height: 4px;
        }

        .diagram-arrow:after {
            content: '';
            position: absolute;
            width: 0;
            height: 0;
            border-style: solid;
        }

        .diagram-text {
            position: absolute;
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--dark-gray);
        }

        .resources {
            background-color: white;
        }

        .resource-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .resource-card {
            background-color: var(--light-gray);
            border-radius: 8px;
            padding: 1.5rem;
            transition: var(--transition);
            box-shadow: var(--card-shadow);
        }

        .resource-card:hover {
            background-color: var(--primary);
            color: white;
            transform: translateY(-5px);
        }

        .resource-card:hover h3, 
        .resource-card:hover a {
            color: white;
        }

        .resource-card h3 {
            color: var(--primary);
            margin-bottom: 1rem;
            transition: var(--transition);
        }

        .resource-card ul {
            list-style-position: inside;
            margin-top: 1rem;
        }

        .resource-card li {
            margin-bottom: 0.5rem;
        }

        .resource-card a {
            color: var(--primary);
            text-decoration: none;
            font-weight: 600;
            transition: var(--transition);
        }

        footer {
            background-color: var(--dark-gray);
            color: white;
            padding: 2rem 0;
            text-align: center;
        }

        .footer-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
        }

        .footer-logo {
            font-size: 1.5rem;
            font-weight: 700;
        }

        .footer-links {
            display: flex;
            list-style: none;
        }

        .footer-links li {
            margin-left: 1.5rem;
        }

        .footer-links a {
            color: white;
            text-decoration: none;
            transition: var(--transition);
        }

        .footer-links a:hover {
            color: var(--accent);
        }

        .copyright {
            width: 100%;
            margin-top: 1.5rem;
            font-size: 0.9rem;
            color: rgba(255, 255, 255, 0.7);
        }

        /* Interactive elements */
        .interactive-demo {
            background-color: white;
            border-radius: 8px;
            box-shadow: var(--card-shadow);
            padding: 2rem;
            margin-top: 2rem;
        }

        .demo-controls {
            display: flex;
            justify-content: center;
            gap: 1rem;
            margin-bottom: 1.5rem;
        }

        .demo-grid {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            grid-template-rows: repeat(5, 1fr);
            gap: 4px;
            width: 100%;
            max-width: 400px;
            margin: 0 auto;
        }

        .grid-cell {
            aspect-ratio: 1;
            background-color: var(--light-gray);
            border-radius: 4px;
            display: flex;
            justify-content: center;
            align-items: center;
            font-weight: bold;
            transition: var(--transition);
            cursor: pointer;
        }

        .agent {
            background-color: var(--primary);
            color: white;
        }

        .goal {
            background-color: var(--success);
            color: white;
        }

        .obstacle {
            background-color: var(--dark-gray);
            color: white;
        }

        .visited {
            background-color: var(--secondary);
            opacity: 0.5;
        }

        .demo-info {
            margin-top: 1.5rem;
            padding: 1rem;
            background-color: var(--light-gray);
            border-radius: 4px;
        }

        .demo-info h4 {
            margin-bottom: 0.5rem;
            color: var(--primary);
        }

        .demo-stats {
            display: flex;
            justify-content: space-around;
            margin-top: 1rem;
        }

        .stat-item {
            text-align: center;
        }

        .stat-value {
            font-size: 1.5rem;
            font-weight: bold;
            color: var(--primary);
        }

        .stat-label {
            font-size: 0.9rem;
            color: var(--dark-gray);
        }

        /* Responsive */
        @media (max-width: 768px) {
            header .container {
                flex-direction: column;
                padding: 1rem;
            }

            nav {
                margin-top: 1rem;
            }

            nav ul {
                flex-wrap: wrap;
                justify-content: center;
            }

            nav li {
                margin: 0.5rem;
            }

            .hero {
                padding: 2rem 0;
            }

            .hero h1 {
                font-size: 2rem;
            }

            .btn {
                display: block;
                margin: 1rem auto;
                width: 80%;
                max-width: 300px;
            }

            .btn-secondary {
                margin-left: auto;
                margin-right: auto;
            }

            .footer-content {
                flex-direction: column;
            }

            .footer-links {
                margin-top: 1rem;
                justify-content: center;
            }

            .footer-links li:first-child {
                margin-left: 0;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="logo">
                <span class="logo-icon">ü§ñ</span>
                <span>RL Guide</span>
            </div>
            <nav>
                <ul>
                    <li><a href="#basics">Basics</a></li>
                    <li><a href="#algorithms">Algorithms</a></li>
                    <li><a href="#applications">Applications</a></li>
                    <li><a href="#process">Process</a></li>
                    <li><a href="#resources">Resources</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <section class="hero">
        <div class="container">
            <h1>Understanding Reinforcement Learning</h1>
            <p>A comprehensive guide to the machine learning paradigm where agents learn to make decisions by interacting with an environment to maximize cumulative rewards.</p>
            <div>
                <a href="#interactive-demo" class="btn">Try Interactive Demo</a>
                <a href="#resources" class="btn btn-secondary">Explore Resources</a>
            </div>
        </div>
    </section>

    <section id="basics">
        <div class="container">
            <h2>The Basics of Reinforcement Learning</h2>
            <div class="features">
                <div class="feature-card">
                    <div class="feature-img">üß†</div>
                    <div class="feature-content">
                        <h3>What is Reinforcement Learning?</h3>
                        <p>Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a cumulative reward signal. Unlike supervised learning, RL doesn't rely on labeled examples but learns through trial and error.</p>
                    </div>
                </div>
                <div class="feature-card">
                    <div class="feature-img">üéÆ</div>
                    <div class="feature-content">
                        <h3>Key Components</h3>
                        <p>RL systems consist of several key components: an <strong>agent</strong> that makes decisions, an <strong>environment</strong> the agent interacts with, <strong>states</strong> that represent the environment, <strong>actions</strong> the agent can take, and <strong>rewards</strong> that provide feedback on the agent's performance.</p>
                    </div>
                </div>
                <div class="feature-card">
                    <div class="feature-img">üéØ</div>
                    <div class="feature-content">
                        <h3>The RL Objective</h3>
                        <p>The primary goal in RL is to learn a policy - a strategy that tells the agent what action to take in each state - that maximizes the expected cumulative reward over time. This involves balancing immediate rewards with long-term benefits through a process called credit assignment.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="algorithms" class="algorithms">
        <div class="container">
            <h2>Common Reinforcement Learning Algorithms</h2>
            <div class="algorithm-cards">
                <div class="algorithm-card">
                    <h3><span>üîÑ</span> Q-Learning</h3>
                    <p>A value-based algorithm that learns the value of taking a specific action in a specific state. It creates a Q-table that maps state-action pairs to expected rewards, allowing the agent to select the best action in any state.</p>
                    <p>Q-Learning is model-free, meaning it doesn't need to understand the environment's dynamics to learn optimal behavior.</p>
                </div>
                <div class="algorithm-card">
                    <h3><span>üîÄ</span> Policy Gradient</h3>
                    <p>A policy-based approach that directly optimizes the policy without using a value function. It updates the policy parameters in the direction of greater expected reward using gradient ascent.</p>
                    <p>Popular in continuous action spaces where Q-Learning becomes impractical.</p>
                </div>
                <div class="algorithm-card">
                    <h3><span>üß©</span> Deep Q-Network (DQN)</h3>
                    <p>Combines Q-Learning with deep neural networks to handle high-dimensional state spaces. DQN uses experience replay and fixed Q-targets to stabilize training.</p>
                    <p>Successfully applied to learn Atari games directly from pixel inputs.</p>
                </div>
                <div class="algorithm-card">
                    <h3><span>‚öñÔ∏è</span> Actor-Critic</h3>
                    <p>A hybrid approach that combines policy-based and value-based methods. The actor (policy) decides which action to take, while the critic (value function) evaluates the action.</p>
                    <p>Reduces variance in policy gradient methods while maintaining reasonable bias.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="applications" class="applications">
        <div class="container">
            <h2>Real-World Applications</h2>
            <div class="application-grid">
                <div class="application-item">
                    <div class="application-img">üöó</div>
                    <div class="application-content">
                        <h3>Autonomous Vehicles</h3>
                        <p>RL helps autonomous vehicles learn optimal driving strategies, navigation, and decision-making in complex traffic scenarios.</p>
                    </div>
                </div>
                <div class="application-item">
                    <div class="application-img">üéÆ</div>
                    <div class="application-content">
                        <h3>Game AI</h3>
                        <p>From chess to Go to complex video games, RL powers AI systems that can match or exceed human performance.</p>
                    </div>
                </div>
                <div class="application-item">
                    <div class="application-img">ü§ñ</div>
                    <div class="application-content">
                        <h3>Robotics</h3>
                        <p>RL enables robots to learn motor skills, manipulation tasks, and adaptive behaviors through physical interaction.</p>
                    </div>
                </div>
                <div class="application-item">
                    <div class="application-img">üìà</div>
                    <div class="application-content">
                        <h3>Finance</h3>
                        <p>Trading algorithms, portfolio management, and risk assessment systems use RL to optimize financial decisions.</p>
                    </div>
                </div>
                <div class="application-item">
                    <div class="application-img">‚ö°</div>
                    <div class="application-content">
                        <h3>Energy Management</h3>
                        <p>Smart grids and energy systems use RL to optimize resource allocation and reduce consumption.</p>
                    </div>
                </div>
                <div class="application-item">
                    <div class="application-img">üè•</div>
                    <div class="application-content">
                        <h3>Healthcare</h3>
                        <p>RL helps optimize treatment plans, drug dosing, and personalized medicine approaches.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="process" class="rl-process">
        <div class="container">
            <h2>The Reinforcement Learning Process</h2>
            <div class="process-diagram">
                <div class="diagram-container">
                    <div class="diagram">
                        <!-- Agent -->
                        <div class="diagram-item" style="top: 120px; left: 50px;">Agent</div>
                        
                        <!-- Environment -->
                        <div class="diagram-item" style="top: 120px; right: 50px;">Environment</div>
                        
                        <!-- Arrows -->
                        <div class="diagram-arrow" style="width: 150px; top: 100px; left: 170px; transform: rotate(0deg);">
                            <div class="diagram-text" style="top: -25px; left: 50px;">Action</div>
                        </div>
                        
                        <div class="diagram-arrow" style="width: 150px; top: 150px; left: 170px; transform: rotate(180deg);">
                            <div class="diagram-text" style="top: 15px; left: 30px;">State, Reward</div>
                        </div>
                    </div>
                    
                    <div class="interactive-demo" id="interactive-demo">
                        <h3>Interactive RL Demo: Gridworld Navigation</h3>
                        <p>Watch an agent learn to navigate a grid environment using Q-learning. The agent (blue) must reach the goal (green) while avoiding obstacles (black).</p>
                        
                        <div class="demo-controls">
                            <button id="start-btn" class="btn">Start Training</button>
                            <button id="reset-btn" class="btn btn-secondary">Reset</button>
                        </div>
                        
                        <div class="demo-grid" id="grid"></div>
                        
                        <div class="demo-info">
                            <h4>Training Progress</h4>
                            <p>The agent learns by trial and error, updating its Q-values based on rewards received.</p>
                            
                            <div class="demo-stats">
                                <div class="stat-item">
                                    <div class="stat-value" id="episode-count">0</div>
                                    <div class="stat-label">Episodes</div>
                                </div>
                                <div class="stat-item">
                                    <div class="stat-value" id="total-reward">0</div>
                                    <div class="stat-label">Total Reward</div>
                                </div>
                                <div class="stat-item">
                                    <div class="stat-value" id="success-rate">0%</div>
                                    <div class="stat-label">Success Rate</div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="resources" class="resources">
        <div class="container">
            <h2>Learning Resources</h2>
            <div class="resource-list">
                <div class="resource-card">
                    <h3>Books</h3>
                    <ul>
                        <li>Reinforcement Learning: An Introduction by Sutton & Barto</li>
                        <li>Deep Reinforcement Learning Hands-On by Maxim Lapan</li>
                        <li>Algorithms for Reinforcement Learning by Csaba Szepesv√°ri</li>
                    </ul>
                </div>
                <div class="resource-card">
                    <h3>Online Courses</h3>
                    <ul>
                        <li>Reinforcement Learning Specialization (Coursera)</li>
                        <li>Deep Reinforcement Learning (UC Berkeley)</li>
                        <li>Practical RL (Higher School of Economics)</li>
                    </ul>
                </div>
                <div class="resource-card">
                    <h3>Libraries & Frameworks</h3>
                    <ul>
                        <li>OpenAI Gym - RL environments</li>
                        <li>Stable Baselines - RL algorithm implementations</li>
                        <li>TensorFlow Agents - RL with TensorFlow</li>
                        <li>PyTorch RL - RL with PyTorch</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <div class="footer-content">
                <div class="footer-logo">ü§ñ RL Guide</div>
                <ul class="footer-links">
                    <li><a href="#basics">Basics</a></li>
                    <li><a href="#algorithms">Algorithms</a></li>
                    <li><a href="#applications">Applications</a></li>
                    <li><a href="#process">Process</a></li>
                    <li><a href="#resources">Resources</a></li>
                </ul>
                <div class="copyright">¬© 2023 RL Guide. All rights reserved.</div>
            </div>
        </div>
    </footer>

    <script>
        // Grid world RL demo
        document.addEventListener('DOMContentLoaded', function() {
            const grid = document.getElementById('grid');
            const startBtn = document.getElementById('start-btn');
            const resetBtn = document.getElementById('reset-btn');
            const episodeCount = document.getElementById('episode-count');
            const totalReward = document.getElementById('total-reward');
            const successRate = document.getElementById('success-rate');
            
            const gridSize = 5;
            let cells = [];
            let agentPos = { x: 0, y: 0 };
            let goalPos = { x: 4, y: 4 };
            let obstacles = [
                { x: 1, y: 1 },
                { x: 2, y: 1 },
                { x: 3, y: 3 },
                { x: 1, y: 3 }
            ];
            
            let isTraining = false;
            let episodes = 0;
            let rewards = 0;
            let successes = 0;
            let qTable = {};
            
            // Initialize grid
            function initGrid() {
                grid.innerHTML = '';
                cells = [];
                
                for (let y = 0; y < gridSize; y++) {
                    for (let x = 0; x < gridSize; x++) {
                        const cell = document.createElement('div');
                        cell.className = 'grid-cell';
                        cell.dataset.x = x;
                        cell.dataset.y = y;
                        
                        // Set initial cell types
                        if (x === agentPos.x && y === agentPos.y) {
                            cell.classList.add('agent');
                            cell.textContent = 'ü§ñ';
                        } else if (x === goalPos.x && y === goalPos.y) {
                            cell.classList.add('goal');
                            cell.textContent = 'üéØ';
                        } else if (obstacles.some(o => o.x === x && o.y === y)) {
                            cell.classList.add('obstacle');
                            cell.textContent = '‚õî';
                        }
                        
                        grid.appendChild(cell);
                        cells.push(cell);
                    }
                }
            }
            
            // Get cell at position
            function getCell(x, y) {
                return cells[y * gridSize + x];
            }
            
            // Update agent position
            function moveAgent(newX, newY) {
                const oldCell = getCell(agentPos.x, agentPos.y);
                oldCell.classList.remove('agent');
                oldCell.classList.add('visited');
                
                agentPos.x = newX;
                agentPos.y = newY;
                
                const newCell = getCell(newX, newY);
                newCell.classList.add('agent');
                newCell.textContent = 'ü§ñ';
            }
            
            // Get available actions at current position
            function getAvailableActions() {
                const actions = [];
                
                // Up
                if (agentPos.y > 0 && !isObstacle(agentPos.x, agentPos.y - 1)) {
                    actions.push('up');
                }
                
                // Right
                if (agentPos.x < gridSize - 1 && !isObstacle(agentPos.x + 1, agentPos.y)) {
                    actions.push('right');
                }
                
                // Down
                if (agentPos.y < gridSize - 1 && !isObstacle(agentPos.x, agentPos.y + 1)) {
                    actions.push('down');
                }
                
                // Left
                if (agentPos.x > 0 && !isObstacle(agentPos.x - 1, agentPos.y)) {
                    actions.push('left');
                }
                
                return actions;
            }
            
            // Check if position is an obstacle
            function isObstacle(x, y) {
                return obstacles.some(o => o.x === x && o.y === y);
            }
            
            // Get state key for Q-table
            function getStateKey(x, y) {
                return `${x},${y}`;
            }
            
            // Get best action from Q-table
            function getBestAction(state) {
                const actions = getAvailableActions();
                
                if (!qTable[state]) {
                    qTable[state] = {};
                    actions.forEach(action => {
                        qTable[state][action] = 0;
                    });
                }
                
                // Epsilon-greedy: sometimes choose random action for exploration
                if (Math.random() < 0.2) {
                    return actions[Math.floor(Math.random() * actions.length)];
                }
                
                // Find action with highest Q-value
                let bestAction = actions[0];
                let bestValue = qTable[state][bestAction] || 0;
                
                for (const action of actions) {
                    const value = qTable[state][action] || 0;
                    if (value > bestValue) {
                        bestValue = value;
                        bestAction = action;
                    }
                }
                
                return bestAction;
            }
            
            // Take action and get reward
            function takeAction(action) {
                let newX = agentPos.x;
                let newY = agentPos.y;
                
                switch (action) {
                    case 'up':
                        newY--;
                        break;
                    case 'right':
                        newX++;
                        break;
                    case 'down':
                        newY++;
                        break;
                    case 'left':
                        newX--;
                        break;
                }
                
                moveAgent(newX, newY);
                
                // Calculate reward
                if (newX === goalPos.x && newY === goalPos.y) {
                    return 100; // Goal reached
                } else {
                    return -1; // Step penalty
                }
            }
            
            // Run one episode of training
            async function runEpisode() {
                // Reset agent position
                agentPos = { x: 0, y: 0 };
                initGrid();
                
                let episodeReward = 0;
                let steps = 0;
                const maxSteps = 25;
                
                while (steps < maxSteps) {
                    // Get current state
                    const state = getStateKey(agentPos.x, agentPos.y);
                    
                    // Choose action
                    const action = getBestAction(state);
                    
                    // Take action
                    const reward = takeAction(action);
                    episodeReward += reward;
                    
                    // Get new state
                    const newState = getStateKey(agentPos.x, agentPos.y);
                    
                    // Update Q-value
                    if (!qTable[state]) qTable[state] = {};
                    if (!qTable[newState]) qTable[newState] = {};
                    
                    const actions = getAvailableActions();
                    actions.forEach(a => {
                        if (!qTable[newState][a]) qTable[newState][a] = 0;
                    });
                    
                    // Q-learning update: Q(s,a) = Q(s,a) + Œ± * [r + Œ≥ * max Q(s',a') - Q(s,a)]
                    const alpha = 0.1; // Learning rate
                    const gamma = 0.9; // Discount factor
                    
                    const maxNextQ = Math.max(...Object.values(qTable[newState]));
                    const oldValue = qTable[state][action] || 0;
                    const newValue = oldValue + alpha * (reward + gamma * maxNextQ - oldValue);
                    
                    qTable[state][action] = newValue;
                    
                    // Check if goal reached
                    if (agentPos.x === goalPos.x && agentPos.y === goalPos.y) {
                        successes++;
                        break;
                    }
                    
                    steps++;
                    
                    // Add delay for visualization
                    await new Promise(resolve => setTimeout(resolve, 200));
                }
                
                episodes++;
                rewards += episodeReward;
                
                // Update stats
                episodeCount.textContent = episodes;
                totalReward.textContent = rewards;
                successRate.textContent = Math.round((successes / episodes) * 100) + '%';
                
                // Continue training if not stopped
                if (isTraining) {
                    setTimeout(runEpisode, 500);
                }
            }
            
            // Initialize
            initGrid();
            
            // Event listeners
            startBtn.addEventListener('click', function() {
                if (!isTraining) {
                    isTraining = true;
                    startBtn.textContent = 'Stop Training';
                    runEpisode();
                } else {
                    isTraining = false;
                    startBtn.textContent = 'Start Training';
                }
            });
            
            resetBtn.addEventListener('click', function() {
                isTraining = false;
                startBtn.textContent = 'Start Training';
                agentPos = { x: 0, y: 0 };
                qTable = {};
                episodes = 0;
                rewards = 0;
                successes = 0;
                
                episodeCount.textContent = '0';
                totalReward.textContent = '0';
                successRate.textContent = '0%';
                
                initGrid();
            });
        });
    </script>
</body>
</html>